# 쇼핑몰 데이터 통합 ETL 파이프라인 프로젝트 총정리

## 프로젝트 개요

### 프로젝트명
H-log 쇼핑몰 데이터 통합 대시보드 시스템

### 프로젝트 기간
2023.01.18 ~ 2023.02.15

### 프로젝트 목적
여러 쇼핑몰 플랫폼(Ably, Cafe24)에 분산된 데이터를 통합 수집하여 사업자가 한 눈에 볼 수 있는 대시보드를 제공하고, 데이터 기반 의사결정을 통한 매출 증대를 목표로 함

## 시스템 아키텍처

### 전체 구조
```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│   Browser   │────▶│    Nginx    │────▶│   Django    │
│  (Client)   │     │   (Port 80) │     │  (Port 8000)│
└─────────────┘     └─────────────┘     └─────────────┘
                                               │
                                               ▼
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│   Airflow   │────▶│  Crawling/  │────▶│  AWS RDS    │
│ (Scheduler) │     │  API Call   │     │   MySQL     │
└─────────────┘     └─────────────┘     └─────────────┘
```

### 데이터 흐름
1. **사용자 등록**: Django 웹에서 각 플랫폼 로그인 정보 등록
2. **자동 수집**: Airflow가 매일 아침 8시에 자동으로 데이터 수집 시작
3. **데이터 추출**: 
   - Ably: Selenium 크롤링으로 판매/상품 데이터 수집
   - Cafe24: API 호출로 카테고리/상품/주문/쿠폰 데이터 수집
4. **데이터 변환**: Pandas DataFrame으로 데이터 정제 및 변환
5. **데이터 적재**: AWS RDS MySQL에 저장
6. **시각화**: Chart.js를 통한 대시보드 제공

## 기술 스택

### Backend
- **Framework**: Django 3.2.3
- **Language**: Python 3.8
- **Database**: AWS RDS MySQL
- **ORM**: Django ORM

### Frontend
- **Template Engine**: Django Templates
- **Styling**: SCSS
- **Charts**: Chart.js
- **JavaScript**: Vanilla JS

### Data Pipeline
- **Orchestration**: Apache Airflow 2.3.1
- **Web Scraping**: Selenium
- **API Integration**: Requests
- **Data Processing**: Pandas, NumPy

### Infrastructure
- **Containerization**: Docker & Docker Compose
- **Web Server**: Nginx
- **Application Server**: Gunicorn
- **Metadata DB**: PostgreSQL (Airflow용)

### DevOps
- **Version Control**: Git
- **Cloud**: AWS (RDS)

## 주요 기능

### 1. 멀티 플랫폼 데이터 통합
- 3개 쇼핑몰 플랫폼(Ably, Cafe24, 스마트스토어) 데이터 통합 관리
- 플랫폼별 특성에 맞는 수집 방식 적용

### 2. 자동화된 ETL 파이프라인
- Airflow DAG로 매일 자동 실행
- Extract → Transform → Load 프로세스 자동화
- 병렬 처리로 효율성 향상

### 3. 실시간 대시보드
- 일/주/월/년 단위 매출 현황
- 제품별 판매 현황

### 4. 확장 가능한 아키텍처
- Docker 기반 마이크로서비스 구조
- 동시 실행 제한으로 안정성 확보
- 모듈화된 코드 구조

## 잘된 점

### 1. 기술적 성과
- **완전 자동화**: 사용자 개입 없이 데이터 수집부터 시각화까지 자동화
- **안정적인 크롤링**: Selenium의 예외 처리와 재시도 로직으로 안정성 확보
- **효율적인 병렬 처리**: ThreadPoolExecutor와 Semaphore를 활용한 동시성 제어
- **Docker 통합**: 단일 명령으로 전체 시스템 구동 가능

### 2. 비즈니스 성과
- **실제 매출 증대**: 데이터 기반 의사결정으로 실제 매출 향상
- **운영 효율화**: 수동 데이터 수집 시간 제로화
- **통합 관리**: 분산된 데이터를 한 곳에서 관리

### 3. 개발 프로세스
- **민첩한 대응**: 사용자 피드백을 빠르게 반영
- **팀워크**: 오프라인 미팅으로 소통 개선
- **문서화**: 상세한 README와 설정 가이드 작성

## 아쉬운 점

### 1. 확장성 한계
- **동시 처리 제한**: 중대규모 사용자(500+) 대응 어려움
- **단일 서버 구조**: 수평적 확장 불가
- **크롤링 의존성**: API가 없는 플랫폼은 크롤링에 의존

### 2. 기술 부채
- **테스트 부족**: 단위 테스트, 통합 테스트 미구현
- **모니터링 부재**: 실시간 성능 모니터링 시스템 없음
- **에러 알림**: 장애 발생 시 즉각적인 알림 체계 부재

### 3. 보안 및 안정성
- **크롤링 차단 위험**: IP 차단에 대한 대응책 부족
- **백업 전략**: 자동 백업 및 복구 시스템 미구현

## 개선 방향

### 단기 개선사항
1. **테스트 코드 작성**: pytest 기반 테스트 커버리지 80% 이상

### 중기 개선사항
1. **Celery + Redis 도입**: 분산 작업 큐 시스템 구축
2. **API Gateway**: 크롤링 의존도 감소를 위한 API 개발
3. **캐싱 전략**: Redis 기반 캐싱으로 성능 향상

### 장기 개선사항
1. **마이크로서비스 전환**: 각 플랫폼별 독립 서비스화
2. **Kubernetes 도입**: 컨테이너 오케스트레이션
3. **ML 기반 예측**: 판매 예측 및 재고 최적화 기능

## 프로젝트 성과

### 정량적 성과
- 데이터 수집 시간: 수동 2시간/일 → 자동 0분
- 동시 처리 능력: 최대 20개 작업 병렬 처리
- 일일 처리 용량: 약 100명 사용자 데이터

### 정성적 성과
- 데이터 기반 의사결정 문화 정착
- 운영팀 업무 효율성 대폭 향상
- 실시간 비즈니스 인사이트 제공

## 회고

이 프로젝트는 실제 비즈니스 문제를 기술로 해결한 의미 있는 경험이었습니다. 특히 다음과 같은 교훈을 얻었습니다:

1. **사용자 중심 개발**: 기술보다 사용자의 실제 필요가 우선
2. **점진적 개선**: 완벽한 시스템보다 동작하는 시스템을 먼저
3. **소통의 중요성**: 온라인보다 오프라인 미팅이 효과적
4. **자동화의 가치**: 반복 작업 자동화로 인한 생산성 향상